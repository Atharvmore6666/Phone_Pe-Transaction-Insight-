# -*- coding: utf-8 -*-
"""Phone_pe.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UggNlB9LqOfR9jr_SA0BimV7rMbLItcx

# **Project Name**    - PhonePe Transaction Insights

##### **Project Type**    - EDA
##### **Contribution**    - Individual
##### **Name**           - Atharva more

# **Project Summary -**

This project analyzes transaction and user data from PhonePe using Python and SQL. Data was extracted from the PhonePe Pulse GitHub repository, cleaned, and transformed for analysis.

Key metrics like transaction volume, user activity, and insurance usage were explored at the state, district, and pincode levels. Visualizations were created using Matplotlib and Seaborn, and insights were derived to support business decisions like customer segmentation, fraud detection, and regional targeting.

 Tools Used
Python 路 SQL 路 Pandas 路 Matplotlib 路 Seaborn 路 Google Colab 路 GitHub

 Deliverables
* Cleaned datasets and analysis notebook

* SQL queries for insights

* Visualizations of trends and top-performing regions

* Streamlit dashboard for interactive exploration

# **GitHub Link -**

Provide your GitHub Link here.

# **Problem Statement**

With the increasing reliance on digital payment systems like PhonePe, understanding the dynamics of transactions, user engagement, and insurance-related data is crucial for improving services and targeting users effectively. This project aims to analyze and visualize aggregated values of payment categories, create maps for total values at state and district levels, and identify top-performing states, districts, and pin codes.

# ***Let's Begin !***

## ***1. Know Your Data***
"""

# Step 1: Clone the PhonePe Pulse GitHub Repository
# !git clone https://github.com/PhonePe/pulse.git

# Step 2: Import Required Libraries
import os
import json
import pandas as pd
from sqlalchemy import create_engine
from pandas import json_normalize
from tqdm import tqdm

# Setup
base_path = "/content/pulse/data"
engine = create_engine('sqlite://', echo=False)

#Aggregated Transaction

def parse_aggregated_transaction():
    path = os.path.join(base_path, 'aggregated/transaction/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        for txn in content['data']['transactionData']:
                            data.append({
                                'State': state,
                                'Year': year,
                                'Quarter': file.strip('.json'),
                                'Transaction_type': txn['name'],
                                'Count': txn['paymentInstruments'][0]['count'],
                                'Amount': txn['paymentInstruments'][0]['amount']
                            })

    df = pd.DataFrame(data)
    df.to_sql('Aggregated_transaction', con=engine, if_exists='replace', index=False)
    return df

#  Aggregated User

def parse_aggregated_user():
    path = os.path.join(base_path, 'aggregated/user/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        if content['data']['usersByDevice']:
                            for user in content['data']['usersByDevice']:
                                data.append({
                                    'State': state,
                                    'Year': year,
                                    'Quarter': file.strip('.json'),
                                    'Brand': user['brand'],
                                    'Count': user['count'],
                                    'Percentage': user['percentage']
                                })

    df = pd.DataFrame(data)
    df.to_sql('Aggregated_user', con=engine, if_exists='replace', index=False)
    return df

# aggregated_insurance

def parse_aggregated_insurance():
    path = os.path.join(base_path, 'aggregated/insurance/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        for txn in content['data']['transactionData']:
                            data.append({
                                'State': state,
                                'Year': year,
                                'Quarter': file.strip('.json'),
                                'Transaction_type': txn['name'],
                                'Count': txn['paymentInstruments'][0]['count'],
                                'Amount': txn['paymentInstruments'][0]['amount']
                            })

    df = pd.DataFrame(data)
    df.to_sql('Aggregated_insurance', con=engine, if_exists='replace', index=False)
    return df

# Map Transaction (Map_map)

def parse_map_transaction():
    path = os.path.join(base_path, 'map/transaction/hover/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        for district in content['data']['hoverDataList']:
                            data.append({
                                'State': state,
                                'Year': year,
                                'Quarter': file.strip('.json'),
                                'District': district['name'],
                                'Count': district['metric'][0]['count'],
                                'Amount': district['metric'][0]['amount']
                            })

    df = pd.DataFrame(data)
    df.to_sql('Map_map', con=engine, if_exists='replace', index=False)
    return df

# Map User

def parse_map_user():
    path = os.path.join(base_path, 'map/user/hover/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        for district in content['data']['hoverData'].keys():
                            dist_data = content['data']['hoverData'][district]
                            data.append({
                                'State': state,
                                'Year': year,
                                'Quarter': file.strip('.json'),
                                'District': district,
                                'RegisteredUsers': dist_data['registeredUsers'],
                                'AppOpens': dist_data.get('appOpens', None)
                            })

    df = pd.DataFrame(data)
    df.to_sql('Map_user', con=engine, if_exists='replace', index=False)
    return df

# Map Insurance

def parse_map_insurance():
    path = os.path.join(base_path, 'map/insurance/hover/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        for district in content['data']['hoverDataList']:
                            data.append({
                                'State': state,
                                'Year': year,
                                'Quarter': file.strip('.json'),
                                'District': district['name'],
                                'Count': district['metric'][0]['count'],
                                'Amount': district['metric'][0]['amount']
                            })

    df = pd.DataFrame(data)
    df.to_sql('Map_insurance', con=engine, if_exists='replace', index=False)
    return df



#ｂ Top Transaction (Top_map)

def parse_top_transaction():
    path = os.path.join(base_path, 'top/transaction/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        for entry in content['data']['districts']:
                            data.append({
                                'State': state,
                                'Year': year,
                                'Quarter': file.strip('.json'),
                                'District': entry['entityName'],
                                'Count': entry['metric']['count'],
                                'Amount': entry['metric']['amount']
                            })

    df = pd.DataFrame(data)
    df.to_sql('Top_map', con=engine, if_exists='replace', index=False)
    return df

# Top User

def parse_top_user():
    path = os.path.join(base_path, 'top/user/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        for entry in content['data']['districts']:
                            data.append({
                                'State': state,
                                'Year': year,
                                'Quarter': file.strip('.json'),
                                'District': entry['name'],
                                'RegisteredUsers': entry['registeredUsers']
                            })

    df = pd.DataFrame(data)
    df.to_sql('Top_user', con=engine, if_exists='replace', index=False)
    return df

# Top Insurance

def parse_top_insurance():
    path = os.path.join(base_path, 'top/insurance/country/india/state')
    data = []

    for state in tqdm(os.listdir(path)):
        for year in os.listdir(os.path.join(path, state)):
            for file in os.listdir(os.path.join(path, state, year)):
                if file.endswith(".json"):
                    with open(os.path.join(path, state, year, file)) as f:
                        content = json.load(f)
                        for entry in content['data']['districts']:
                            data.append({
                                'State': state,
                                'Year': year,
                                'Quarter': file.strip('.json'),
                                'District': entry['entityName'],
                                'Count': entry['metric']['count'],
                                'Amount': entry['metric']['amount']
                            })

    df = pd.DataFrame(data)
    df.to_sql('Top_insurance', con=engine, if_exists='replace', index=False)
    return df

df1 = parse_aggregated_transaction()
df2 = parse_aggregated_user()
df3 = parse_aggregated_insurance()
df4 = parse_map_user()
df5 = parse_map_transaction()
df6 = parse_map_insurance()
df7 = parse_top_user()
df8 = parse_top_transaction()
df9 = parse_top_insurance()







"""### Dataset First View"""

df1.head(10)

df2.head(10)

df3.head(10)

df4.head(10)

df5.head(10)

df6.head(10)

df7.head(10)

df8.head(10)

df9.head(10)

"""### Dataset Rows & Columns count"""

# Dataset Rows & Columns count
# Dataset Rows & Columns count
print("Shape of df1:", df1.shape)
print("Shape of df2:", df2.shape)
print("Shape of df3:", df3.shape)
print("Shape of df4:", df4.shape)
print("Shape of df5:", df5.shape)
print("Shape of df6:", df6.shape)
print("Shape of df7:", df7.shape)
print("Shape of df8:", df8.shape)
print("Shape of df9:", df9.shape)

"""### Dataset Information"""

# Dataset Info
# Dataset Info
print("Info for df1:")
df1.info()
print("\nInfo for df2:")
df2.info()
print("\nInfo for df3:")
df3.info()
print("\nInfo for df4:")
df4.info()
print("\nInfo for df5:")
df5.info()
print("\nInfo for df6:")
df6.info()
print("\nInfo for df7:")
df7.info()
print("\nInfo for df8:")
df8.info()
print("\nInfo for df9:")
df9.info()

"""#### Duplicate Values"""

# Dataset Duplicate Value Count
print("Duplicate count for df1:", df1.duplicated().sum())
print("Duplicate count for df2:", df2.duplicated().sum())
print("Duplicate count for df3:", df3.duplicated().sum())
print("Duplicate count for df4:", df4.duplicated().sum())
print("Duplicate count for df5:", df5.duplicated().sum())
print("Duplicate count for df6:", df6.duplicated().sum())
print("Duplicate count for df7:", df7.duplicated().sum())
print("Duplicate count for df8:", df8.duplicated().sum())
print("Duplicate count for df9:", df9.duplicated().sum())

"""#### Missing Values/Null Values"""

# Missing Values/Null Values Count

print("Missing values for df1:\n", df1.isnull().sum())
print("\nMissing values for df2:\n", df2.isnull().sum())
print("\nMissing values for df3:\n", df3.isnull().sum())
print("\nMissing values for df4:\n", df4.isnull().sum())
print("\nMissing values for df5:\n", df5.isnull().sum())
print("\nMissing values for df6:\n", df6.isnull().sum())
print("\nMissing values for df7:\n", df7.isnull().sum())
print("\nMissing values for df8:\n", df8.isnull().sum())
print("\nMissing values for df9:\n", df9.isnull().sum())

# Visualizing the missing values

"""### What did you know about your dataset?

* The data has been successfully cloned from the PhonePe Pulse GitHub repository.
* Nine pandas DataFrames (df1 to df9) have been created by parsing the JSON files from the repository. These DataFrames represent different types of PhonePe data (aggregated transactions, users, and insurance, as well as map and top data for transactions, users, and insurance).
* The .head() of each DataFrame has been displayed, giving a glimpse of the data structure and content for each.
* The shape of each DataFrame has been determined, showing the number of rows and columns in each dataset.
* It has been confirmed that there are no duplicate rows in any of the nine DataFrames.
* It has also been confirmed that there are no missing values in any of the columns across all nine DataFrames.
* In summary, the datasets are loaded, their basic structure is known, and they appear to be clean with no duplicate rows or missing values.

## ***2. Understanding Your Variables***
"""

# Dataset Describe

print("Description for df1:\n", df1.describe())
print("\nDescription for df2:\n", df2.describe())
print("\nDescription for df3:\n", df3.describe())
print("\nDescription for df4:\n", df4.describe())
print("\nDescription for df5:\n", df5.describe())
print("\nDescription for df6:\n", df6.describe())
print("\nDescription for df7:\n", df7.describe())
print("\nDescription for df8:\n", df8.describe())
print("\nDescription for df9:\n", df9.describe())

"""### Buisness case study"""

#  Decoding Transaction Dynamics
# Goal: Understand how payment types perform over time across states.

# @title Default title text
query_transaction_dynamics = '''
SELECT
    State,
    Year,
    Quarter,
    Transaction_type,
    SUM(Count) AS Total_Transactions,
    SUM(Amount) AS Total_Amount
FROM Aggregated_transaction
GROUP BY State, Year, Quarter, Transaction_type
ORDER BY Year, Quarter
'''
df_transaction_dynamics = pd.read_sql_query(query_transaction_dynamics, engine)

df_transaction_dynamics

import seaborn as sns
import matplotlib.pyplot as plt

# Group and plot total amount by year and type
grouped_txn = df_transaction_dynamics.groupby(['Year', 'Transaction_type'])['Total_Amount'].sum().reset_index()

plt.figure(figsize=(12,6))
sns.barplot(data=grouped_txn, x='Year', y='Total_Amount', hue='Transaction_type')
plt.title('Total Transaction Amount by Type (Yearly Aggregated)')
plt.ylabel('Total Amount (INR)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Device Dominance & User Engagement
# Goal: Discover which mobile brands lead in user registration and engagement.

query_device_dominance = '''
SELECT
    State,
    Year,
    Quarter,
    Brand,
    SUM(Count) AS Registered_Users,
    ROUND(AVG(Percentage), 2) AS Avg_Percentage
FROM Aggregated_user
GROUP BY State, Year, Quarter, Brand
ORDER BY Registered_Users DESC
'''
df_device_dominance = pd.read_sql_query(query_device_dominance, engine)

df_device_dominance.head(10)

# Top 5 Brands by Total Registered Users
top_brands = df_device_dominance.groupby('Brand')['Registered_Users'].sum().sort_values(ascending=False).head(5).reset_index()

plt.figure(figsize=(10,5))
sns.barplot(data=top_brands, x='Brand', y='Registered_Users', palette='viridis')
plt.title('Top 5 Mobile Brands by Registered Users')
plt.xlabel('Brand')
plt.ylabel('Total Registered Users')
plt.tight_layout()
plt.show()

top_engagement = df_device_dominance.groupby('Brand')['Avg_Percentage'].mean().sort_values(ascending=False).head(5).reset_index()

plt.figure(figsize=(10,5))
sns.barplot(data=top_engagement, x='Brand', y='Avg_Percentage', palette='coolwarm')
plt.title('Top 5 Brands by Engagement %')
plt.xlabel('Brand')
plt.ylabel('Avg % of Active Users')
plt.tight_layout()
plt.show()

# Insurance Penetration & Growth Potential
# Goal: Analyze growth and penetration of insurance transactions.

query_insurance_growth = '''
SELECT
    State,
    Year,
    Quarter,
    Transaction_type,
    SUM(Count) AS Insurance_Count,
    SUM(Amount) AS Insurance_Amount
FROM Aggregated_insurance
GROUP BY State, Year, Quarter, Transaction_type
ORDER BY Year, Quarter
'''
df_insurance_growth = pd.read_sql_query(query_insurance_growth, engine)

df_insurance_growth.head(10)

# Top 10 States by Total Insurance Amount
top_insurance = df_insurance_growth.groupby('State')['Insurance_Amount'].sum().sort_values(ascending=False).head(10).reset_index()

plt.figure(figsize=(12,5))
sns.barplot(data=top_insurance, x='State', y='Insurance_Amount', palette='magma')
plt.xticks(rotation=45)
plt.title('Top 10 States by Insurance Amount')
plt.ylabel('Insurance Transaction Value')
plt.tight_layout()
plt.show()

# Filter one top state for trend
maha = df_insurance_growth[df_insurance_growth['State'] == 'maharashtra']

plt.figure(figsize=(12,6))
sns.lineplot(data=maha, x='Quarter', y='Insurance_Amount', hue='Year', marker='o')
plt.title('Maharashtra Insurance Transaction Trend')
plt.tight_layout()
plt.show()

# User Engagement and Growth Strategy
# Goal: Evaluate app usage vs. registered users.

query_user_engagement = '''
SELECT
    State,
    SUM(RegisteredUsers) AS Total_Users,
    SUM(AppOpens) AS Total_AppOpens
FROM Map_user
GROUP BY State
ORDER BY Total_AppOpens DESC
'''
df_user_engagement = pd.read_sql_query(query_user_engagement, engine)



# Add Engagement Ratio column
df_user_engagement['Engagement_Ratio'] = df_user_engagement['Total_AppOpens'] / df_user_engagement['Total_Users']

# Top 10 Engaged States
top_engaged = df_user_engagement.sort_values('Engagement_Ratio', ascending=False).head(10)

plt.figure(figsize=(12,6))
sns.barplot(data=top_engaged, x='Engagement_Ratio', y='State', palette='summer')
plt.title('Top 10 States by User Engagement Ratio (App Opens per User)')
plt.ylabel('App Opens per Registered User')
plt.tight_layout()
plt.show()

# Transaction Analysis Across States and Districts
# Goal: Identify top-performing areas by transaction value.

query_transaction_by_district = '''
SELECT
    State,
    District,
    SUM(Amount) AS Total_Amount,
    SUM(Count) AS Total_Transactions
FROM Top_map
GROUP BY State, District
ORDER BY Total_Amount DESC
LIMIT 20
'''
df_top_districts = pd.read_sql_query(query_transaction_by_district, engine)

df_top_districts

# Top 10 Districts by Transaction Amount
plt.figure(figsize=(14,6))
sns.barplot(data=df_top_districts.head(10), x='District', y='Total_Amount', palette='plasma')
plt.title('Top 10 Districts by Transaction Amount')
plt.ylabel('Total Transaction Amount (INR)')
plt.xlabel('District')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()



"""# **Conclusion**

### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***
"""



